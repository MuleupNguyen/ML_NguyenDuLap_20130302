{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MuleupNguyen/ML_NguyenDuLap_20130302/blob/main/Lab_4_20130302_NguyenDuLap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# This lab is to continous dealing with **Logistic Regression**, **kNN**, and **Decision Tree** alogirthms applied to classification tasks. \n",
        "\n",
        "*   **Deadline: 23:59, 12/03/2023**\n",
        "\n"
      ],
      "metadata": {
        "id": "LMzehe0sy5wr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import libraries"
      ],
      "metadata": {
        "id": "H4nJmxp9zGX4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "DoVWQ8AEyc-C"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.datasets import fetch_openml\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 1. \n",
        "Apply **LogisticRegression** to iris dataset which aims at classifying species of iris based on sepal_length (chiều dài đài hoa), sepal_width, petal_length (chiều dài cánh hoa), petal_width. The species are '**setosa**' '**versicolor**' and '**virginica**'. \n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "data4 = datasets.load_iris()\n",
        "```\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "kNv07ARGzOUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "data4 = datasets.load_iris()\n",
        "classifier  = LogisticRegression()\n",
        "X = data4.data\n",
        "y = data4.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "classifier.fit(X_train,y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "print(cm)\n",
        "print(accuracy_score(y_test,y_pred))"
      ],
      "metadata": {
        "id": "sOsg77IBzEyo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "636e6661-ee55-4d26-c51d-1e83e7cd8b98"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[16  0  0]\n",
            " [ 0 17  1]\n",
            " [ 0  0 11]]\n",
            "0.9777777777777777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 2. \n",
        "Apply LogisticRegression to **MNIST** dataset (mnist.csv) which aims at classifying handwritten digits. Dataset includes 784 pixels values of images (28x28). \n",
        "\n",
        "\n",
        "```\n",
        "from sklearn import datasets\n",
        "# load the MNIST digits dataset\n",
        "mnist = datasets.load_digits()\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "S43IoUT-0OQq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = datasets.load_digits()\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "y_pred = classifier.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(confusion_matrix(y_test, y_pred))\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "id": "_xhPpF5b033h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cf9ac64-7623-4bfd-9a69-bede096ed6f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[45  0  0  0  0  0  0  0  0  0]\n",
            " [ 0 49  0  0  0  0  0  0  2  1]\n",
            " [ 0  2 49  2  0  0  0  0  0  0]\n",
            " [ 0  0  0 52  0  0  0  0  1  1]\n",
            " [ 0  0  0  0 47  0  0  1  0  0]\n",
            " [ 0  0  0  0  0 55  0  0  0  2]\n",
            " [ 0  1  0  0  0  0 59  0  0  0]\n",
            " [ 0  0  0  1  1  0  0 51  0  0]\n",
            " [ 0  3  1  0  0  0  0  0 53  4]\n",
            " [ 0  0  0  0  0  1  0  0  1 55]]\n",
            "Accuracy: 0.9537037037037037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 3. \n",
        "Apply another classification algorithm named kNN, which is an instance classifcation model. \n",
        "*  3.1. Perform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "\n",
        "*   3.2. Then compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "Rti2y0Wz2KY9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "iris = load_iris()\n",
        "\n",
        "\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\n",
        "\n",
        "\n",
        "for k in range(1, 30, 2):\n",
        "    knn_model = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn_model.fit(X_train, y_train)\n",
        "    y_pred = knn_model.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall_knn = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1_knn = f1_score(y_test, y_pred, average='weighted')\n",
        "    print(\"kNN with k =\", k)\n",
        "    print(\"Accuracy:\", accuracy)\n",
        "    print(\"Precision:\", precision)\n",
        "    print(\"Recall:\", recall_knn)\n",
        "    print(\"F1-score:\", f1_knn)\n",
        "    print()\n",
        "\n",
        "lr_model = LogisticRegression()\n",
        "lr_model.fit(X_train, y_train)\n",
        "y_pred_lr = lr_model.predict(X_test)\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "precision_lr = precision_score(y_test, y_pred_lr, average='weighted')\n",
        "recall_lr = recall_score(y_test, y_pred_lr, average='weighted')\n",
        "f1_lr = f1_score(y_test, y_pred_lr, average='weighted')\n",
        "print(\"Logistic Regression\")\n",
        "print(\"Accuracy:\", accuracy_lr)\n",
        "print(\"Precision:\", precision_lr)\n",
        "print(\"Recall:\", recall_lr)\n",
        "print(\"F1-score:\", f1_lr)"
      ],
      "metadata": {
        "id": "13LkkfpS2ZUR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3c875b-cd38-40a0-ff80-bd2a6f843159"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "kNN with k = 1\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 3\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 5\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 7\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 9\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 11\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 13\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 15\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 17\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 19\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 21\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 23\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 25\n",
            "Accuracy: 0.9555555555555556\n",
            "Precision: 0.9623931623931624\n",
            "Recall: 0.9555555555555556\n",
            "F1-score: 0.9561002178649236\n",
            "\n",
            "kNN with k = 27\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n",
            "\n",
            "kNN with k = 29\n",
            "Accuracy: 0.9555555555555556\n",
            "Precision: 0.9623931623931624\n",
            "Recall: 0.9555555555555556\n",
            "F1-score: 0.9561002178649236\n",
            "\n",
            "Logistic Regression\n",
            "Accuracy: 0.9777777777777777\n",
            "Precision: 0.9796296296296295\n",
            "Recall: 0.9777777777777777\n",
            "F1-score: 0.9779434092477569\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 4. \n",
        "Similar to Task 3, apply kNN algorithm to **mnist** dataset which included in datasets of sklearn API.\n",
        "*  4.1.\tPerform kNN algorithm to Iris dataset with k={1, 3, 5, …, 29}. Select the best value of k.\n",
        "*  4.2.\tThen compare the obtained results with those using Logistic regression (based on metrics: accuracy, precision, recall, f1 measure).\n"
      ],
      "metadata": {
        "id": "b52OPWPD2afi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "mnist = fetch_openml('mnist_784')\n",
        "X = mnist.data\n",
        "y = mnist.target\n",
        "\n",
        "X = X / 255.0\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "k_values = list(range(1, 30, 2))\n",
        "\n",
        "scores = []\n",
        "for k in k_values:\n",
        "    knn = KNeighborsClassifier(n_neighbors=k)\n",
        "    knn.fit(X_train, y_train)\n",
        "    y_pred = knn.predict(X_test)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    scores.append(score)\n",
        "    print(f\"k={k}: {score}\")\n",
        "best_k = k_values[scores.index(max(scores))]\n",
        "print(f\"Best k value: {best_k}\")\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred = lr.predict(X_test)\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "print(\"Logistic Regression Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred, average='weighted')}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred, average='weighted')}\")\n",
        "print(f\"F1 score: {f1_score(y_test, y_pred, average='weighted')}\")\n",
        "print(\"\\nkNN Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_knn, average='weighted')}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_knn, average='weighted')}\")\n",
        "print(f\"F1 score: {f1_score(y_test, y_pred_knn, average='weighted')}\")\n"
      ],
      "metadata": {
        "id": "Rw_-8FIf2KxW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47e207c0-9308-4748-8d6d-02bd211a8296"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "k=1: 0.972\n",
            "k=3: 0.9712857142857143\n",
            "k=5: 0.9700714285714286\n",
            "k=7: 0.9687142857142857\n",
            "k=9: 0.9674285714285714\n",
            "k=11: 0.9654285714285714\n",
            "k=13: 0.965\n",
            "k=15: 0.9638571428571429\n",
            "k=17: 0.9629285714285715\n",
            "k=19: 0.9625714285714285\n",
            "k=21: 0.9610714285714286\n",
            "k=23: 0.9603571428571429\n",
            "k=25: 0.9595\n",
            "k=27: 0.9584285714285714\n",
            "k=29: 0.9578571428571429\n",
            "Best k value: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Metrics:\n",
            "Accuracy: 0.9202857142857143\n",
            "Precision: 0.9201366664287828\n",
            "Recall: 0.9202857142857143\n",
            "F1 score: 0.9201396698129616\n",
            "\n",
            "kNN Metrics:\n",
            "Accuracy: 0.9712857142857143\n",
            "Precision: 0.9714135351097153\n",
            "Recall: 0.9712857142857143\n",
            "F1 score: 0.9712253100533883\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Task 5. \n",
        "Compare the performance of selected classification algorithms (**Decision Treen, kNN, and Logistic Regression**) to ***spam detection***. The dataset can be accessed from the link: http://archive.ics.uci.edu/ml/datasets/Spambase \n",
        "Attribute Information:\n",
        "The last column of 'spambase.csv denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. Most of the attributes indicate whether a particular word or character was frequently occuring in the e-mail. The run-length attributes (55-57) measure the length of sequences of consecutive capital letters. For the statistical measures of each attribute, see the end of this file. Here are the definitions of the attributes: \n",
        "*  48 continuous real [0,100] attributes of type word_freq_WORD \n",
        "= percentage of words in the e-mail that match WORD, i.e. 100 * (number of times the WORD appears in the e-mail) / total number of words in e-mail. A \"word\" in this case is any string of alphanumeric characters bounded by non-alphanumeric characters or end-of-string. **Example**: word_freq_address: percentage of words in the e-mail that match ADDRESS.\n",
        "*  6 continuous real [0,100] attributes of type char_freq_CHAR] \n",
        "= percentage of characters in the e-mail that match CHAR, i.e. 100 * (number of CHAR occurences) / total characters in e-mail\n",
        "*  1 continuous real [1,...] attribute of type capital_run_length_average \n",
        "= average length of uninterrupted sequences of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_longest \n",
        "= length of longest uninterrupted sequence of capital letters\n",
        "*  1 continuous integer [1,...] attribute of type capital_run_length_total = sum of length of uninterrupted sequences of capital letters = total number of capital letters in the e-mail\n",
        "*  1 nominal {0,1} class attribute of type spam = denotes whether the e-mail was considered spam (1) or not (0), i.e. unsolicited commercial e-mail. \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "In order to compare the performance of selected algorithms, some common metrics including **accuracy, precision, recall, f1 measures** could be used.\n"
      ],
      "metadata": {
        "id": "MVzSk4l505E0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# code\n",
        "data = pd.read_csv(\"http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\", header=None)\n",
        "X = data.iloc[:, :-1].values\n",
        "y = data.iloc[:, -1].values\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "dt = DecisionTreeClassifier(random_state=42)\n",
        "dt.fit(X_train, y_train)\n",
        "y_pred_dt = dt.predict(X_test)\n",
        "dt_accuracy = accuracy_score(y_test, y_pred_dt)\n",
        "print(f\"Decision Tree accuracy: {dt_accuracy}\")\n",
        "knn = KNeighborsClassifier(n_neighbors=3)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred_knn = knn.predict(X_test)\n",
        "knn_accuracy = accuracy_score(y_test, y_pred_knn)\n",
        "print(f\"kNN accuracy: {knn_accuracy}\")\n",
        "lr = LogisticRegression(random_state=42)\n",
        "lr.fit(X_train, y_train)\n",
        "y_pred_lr = lr.predict(X_test)\n",
        "print(\"Decision Tree Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_dt)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_dt)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_dt)}\")\n",
        "print(f\"F1 score: {f1_score(y_test, y_pred_dt)}\")\n",
        "\n",
        "print(\"\\nkNN Metrics:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_knn)}\")\n",
        "print(f\"Precision: {precision_score(y_test, y_pred_knn)}\")\n",
        "print(f\"Recall: {recall_score(y_test, y_pred_knn)}\")\n",
        "print(f\"F1 score: {f1_score(y_test, y_pred_knn)}\")"
      ],
      "metadata": {
        "id": "W_1v_ivR2f6D",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9143cc18-4cb9-45c1-867d-e8e9fe947838"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Decision Tree accuracy: 0.9185667752442996\n",
            "kNN accuracy: 0.7882736156351792\n",
            "Decision Tree Metrics:\n",
            "Accuracy: 0.9185667752442996\n",
            "Precision: 0.92\n",
            "Recall: 0.8846153846153846\n",
            "F1 score: 0.9019607843137256\n",
            "\n",
            "kNN Metrics:\n",
            "Accuracy: 0.7882736156351792\n",
            "Precision: 0.7809798270893372\n",
            "Recall: 0.6948717948717948\n",
            "F1 score: 0.7354138398914519\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.9/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Finally,\n",
        "Save a copy in your Github. Remember renaming the notebook."
      ],
      "metadata": {
        "id": "Ok7RGkea_b7n"
      }
    }
  ]
}